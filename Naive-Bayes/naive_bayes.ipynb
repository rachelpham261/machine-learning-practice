{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCZYXwtCsL_y"
   },
   "source": [
    "CA02: This is a eMail Spam Classifers that uses Naive Bayes supervised machine learning algorithm. \n",
    "\n",
    "In this assignment you will ...\n",
    "1. Complete the code such a way that it works correctly with this given parts of the program.\n",
    "2. Explain as clearly as possible what each part of the code is doing. Use \"Markdown\" texts and code commenting to explain the code\n",
    "\n",
    "IMPORTANT NOTE:\n",
    "\n",
    "The path of your data folders 'train-mails' and 'test-mails' must be './train-mails' and './test-mails'. This means you must have your .ipynb file and these folders in the SAME FOLDER in your laptop or Google Drive. The reason for doing this is, this way the peer reviewes and I would be able to run your code from our computers using this exact same relative path, irrespective of our folder hierarchy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4p_DvtT7sOIr",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# import GaussianNB from sklearn which implements the Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# import accuracy_score from sklearn to measure the accuracy of the model\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful functions for processing data\n",
    "`make_Dictionary` creates a dictionary of the 3000 most common words and their frequency counts from a directory of text files.\n",
    "\n",
    "`extract_features` returns feature matrices and labels from emails in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jjKF0nIMwz8_",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def make_Dictionary(root_dir):\n",
    "  \"\"\"\n",
    "    This function creates a dictionary of words from the emails in the specified directory.\n",
    "    It reads all the emails, tokenizes them into words, and counts the frequency of each word.\n",
    "    Non-alphabetic characters and single-character words are removed.\n",
    "    Finally, it returns a dictionary of the 3000 most common words.\n",
    "    \n",
    "    Args:\n",
    "    root_dir (str): The directory containing the email files.\n",
    "    \n",
    "    Returns:\n",
    "    list: A dictionary of the 3000 most common words and their frequency counts.\n",
    "  \"\"\"\n",
    "  all_words = []\n",
    "  # get the path of all emails\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)]\n",
    "  # loop through each email and read it\n",
    "  for mail in emails:\n",
    "    with open(mail) as m:\n",
    "      # loop through each line of the email\n",
    "      for line in m:\n",
    "        # split the line into words and add them to the list of all words\n",
    "        words = line.split()\n",
    "        all_words += words\n",
    "  # create a dictionary of the words and their frequency counts\n",
    "  dictionary = Counter(all_words)\n",
    "  # initialize a list to store the words that will be removed\n",
    "  list_to_remove = list(dictionary)\n",
    "\n",
    "  for item in list_to_remove:\n",
    "    # remove non-alphabetic characters and single-character words\n",
    "    if item.isalpha() == False:\n",
    "      del dictionary[item]\n",
    "    elif len(item) == 1:\n",
    "      del dictionary[item]\n",
    "  # only keep the 3000 most common words\n",
    "  dictionary = dictionary.most_common(3000)\n",
    "  return dictionary\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "dmVW5xNlyOFc",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir):\n",
    "  \"\"\"\n",
    "    This function extracts feature matrix and labels from emails in the given directory.\n",
    "    It reads all the files, extracts features based on the frequency of each word in the dictionary,\n",
    "    and assigns a label (0 for ham, 1 for spam).\n",
    "    \n",
    "    Args:\n",
    "    mail_dir (str): The directory containing the email files.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the features matrix and the labels array.\n",
    "  \"\"\"\n",
    "  # List all the files in the directory\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]\n",
    "  # Initialize a matrix with zeros, with rows as files and columns as dictionary words\n",
    "  features_matrix = np.zeros((len(files),3000))\n",
    "  # Initialize an array with zeros to hold the label of each email (spam or ham)\n",
    "  train_labels = np.zeros(len(files))\n",
    "  count = 1;\n",
    "  # Index to keep track of which document is being processed\n",
    "  docID = 0;\n",
    "  # Loop through each file in the directory\n",
    "  for fil in files:\n",
    "    with open(fil) as fi:\n",
    "      # Read each line in the email file\n",
    "      for i, line in enumerate(fi):\n",
    "        # The content of the email is expected to be at the 3rd line\n",
    "        if i ==2:\n",
    "          # Split the line into words\n",
    "          words = line.split()\n",
    "          # Iterate through each word in the line\n",
    "          for word in words:\n",
    "            # Find the word ID if the word is in the dictionary\n",
    "            wordID = 0\n",
    "            for i, d in enumerate(dictionary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                # Increment the count of the word in the features matrix\n",
    "                features_matrix[docID,wordID] = words.count(word)\n",
    "      # By default, label the email as ham (0)\n",
    "      train_labels[docID] = 0;\n",
    "      # Extract the file name and check if it starts with 'spmsg'\n",
    "      filepathTokens = fil.split('/')\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      # If the file name starts with 'spmsg', label the email as spam (1)\n",
    "      if lastToken.startswith(\"spmsg\"):\n",
    "        train_labels[docID] = 1;\n",
    "        count = count + 1\n",
    "      # Move to the next document\n",
    "      docID = docID + 1\n",
    "  return features_matrix, train_labels                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set training and test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zoq-rE7Mx0pp",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = './train-mails'\n",
    "TEST_DIR = './test-mails'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary from training directory and transform training and test data to feature matrices and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n"
     ]
    }
   ],
   "source": [
    "dictionary = make_Dictionary(TRAIN_DIR)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = extract_features(TRAIN_DIR)\n",
    "test_features_matrix, test_labels = extract_features(TEST_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Naive Bayes model and measure its accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127480,
     "status": "ok",
     "timestamp": 1578886833446,
     "user": {
      "displayName": "Arin Brahma",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBXGIW7FvUnbm_QmEFGh4rLebuLHNZgc8PuNinU=s64",
      "userId": "05299564422021375910"
     },
     "user_tz": 480
    },
    "id": "134lmhauyQxE",
    "outputId": "83cce6a6-aff5-4e93-ef0a-700606437aa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using Gaussian Naive Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "Accuracy: 0.9653846153846154\n"
     ]
    }
   ],
   "source": [
    "# Training the Naive Bayes model\n",
    "model = GaussianNB()\n",
    "print ('Training Model using Gaussian Naive Bayes algorithm .....')\n",
    "model.fit(features_matrix, labels)\n",
    "print ('Training completed')\n",
    "\n",
    "# Predicting the labels for the test data\n",
    "print ('testing trained model to predict Test Data labels')\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "\n",
    "# Calculating the accuracy of the model\n",
    "print ('Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:')\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M5_mPrvN586A"
   },
   "source": [
    "======================= END OF PROGRAM ========================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOaSi3qlFUlqTup/1esXCKD",
   "collapsed_sections": [],
   "name": "naive_bayes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
